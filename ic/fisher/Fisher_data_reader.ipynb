{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the files with Market Iterations: These are for multiple auctions in one run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle_file(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directing to the path where the results are stored adn read all the pickle files (Market 0 to end market), extracting the market times\n",
    "# and storing the data in a list of dictionaries. The list is then converted to a DataFrame for easier visualization.\n",
    "current_dir = os.getcwd()\n",
    "parent_folder = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "folder_path = os.path.join(\n",
    "    parent_folder,\n",
    "    \"results\",\n",
    "    \"modified_bidbudget_toulouse_case3_withC_cap5_withReturn_3_highcap_fisher_b-50.0_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250204_111131\",\n",
    "    \"results\"\n",
    ")\n",
    "\n",
    "\n",
    "fisher_files = sorted(glob.glob(os.path.join(folder_path, \"fisher_data_*.pkl\")))\n",
    "fisher_after_files = sorted(glob.glob(os.path.join(folder_path, \"fisher_data_after_*.pkl\")))\n",
    "\n",
    "# Extract the market auction time from filenames\n",
    "def extract_time(filename):\n",
    "    return int(filename.split(\"_\")[-1].split(\".\")[0])  # Extracts the number from fisher_data_X.pkl\n",
    "\n",
    "\n",
    "fisher_data_list = []\n",
    "after_fisher_data_list = []\n",
    "\n",
    "# Iterate over paired files\n",
    "for fisher_file, fisher_after_file in zip(fisher_files, fisher_after_files):\n",
    "    fisher_data = read_pickle_file(fisher_file)\n",
    "    end_of_market_data = read_pickle_file(fisher_after_file)\n",
    "\n",
    "    if fisher_data is None or end_of_market_data is None:\n",
    "        continue  # Skip if reading failed\n",
    "\n",
    "    market_time = extract_time(fisher_file)\n",
    "\n",
    "    # Extract necessary data from Fisher Market (Before Transactions)\n",
    "    prices = fisher_data[\"prices\"]\n",
    "    goods_list = fisher_data[\"goods_list\"]\n",
    "\n",
    "    # Extract necessary data from End of Market (After Transactions)\n",
    "    market_data = end_of_market_data[\"market_data\"]\n",
    "    agents_data = end_of_market_data[\"agents_data\"]\n",
    "\n",
    "    # Extract market-level data\n",
    "    end_capacities = market_data[\"capacity\"]\n",
    "    initial_capacities = market_data[\"original_capacity\"]\n",
    "    end_prices = market_data[\"prices\"]  # Prices after transactions (if they change)\n",
    "\n",
    "    print(f\"\\nüîé Processing Market Time: {market_time}\")\n",
    "    print(f\"  üìå Found {len(fisher_data['desired_goods'])} agents\")\n",
    "\n",
    "    for agent, agent_data in fisher_data[\"desired_goods\"].items():\n",
    "        desired_indx = agent_data['desired_transit_edges_idx'][0]  # Directly access\n",
    "\n",
    "        try:\n",
    "            # Data before transactions (Fisher Market)\n",
    "            fisher_data_list.append({\n",
    "                \"Market_Time\": market_time,\n",
    "                \"Agent\": agent,\n",
    "                \"Edge_Index\": desired_indx,\n",
    "                \"Price\": prices[desired_indx],  # Price before transaction\n",
    "                \"Initial_Capacity\": initial_capacities[desired_indx],  # Starting capacity\n",
    "                \"Good\": goods_list[desired_indx][1],\n",
    "                \"Data_Type\": \"Fisher\"\n",
    "            })\n",
    "\n",
    "            # Extract agent-specific information after the market transaction\n",
    "            agent_final_allocation = agents_data[agent].get(\"final_allocation\", {})\n",
    "            agent_payment = agents_data[agent].get(\"payment\", 0)\n",
    "            agent_valuation = agents_data[agent].get(\"valuation\", {})\n",
    "\n",
    "            # Data after transactions (After Fisher Market)\n",
    "            after_fisher_data_list.append({\n",
    "                \"Market_Time\": market_time,\n",
    "                \"Agent\": agent,\n",
    "                \"Edge_Index\": desired_indx,\n",
    "                \"Price\": end_prices[desired_indx],  # Final price after auction\n",
    "                \"End_Capacity\": end_capacities[desired_indx],  # Capacity after auction\n",
    "                \"Good\": goods_list[desired_indx][1],\n",
    "                \"Final_Goods_allocated\": agents_data[agent][\"agent_goods_list\"],  # Final goods allocated\n",
    "                \"Final_goods_vector\": agent_final_allocation,\n",
    "                \"Payment\": agent_payment,\n",
    "                \"Data_Type\": \"After_Fisher\"\n",
    "            })\n",
    "        except KeyError as e:\n",
    "            print(f\"    ‚ùå Skipping {agent}: Key {e} not found in dataset!\")\n",
    "\n",
    "# Create DataFrames\n",
    "df_fisher = pd.DataFrame(fisher_data_list)\n",
    "df_after_fisher = pd.DataFrame(after_fisher_data_list)\n",
    "\n",
    "# ## uncomment below if you want to see the entire dataframe\n",
    "# # pd.set_option('display.max_rows', None)  # Show all rows\n",
    "# # pd.set_option('display.max_columns', None)  # Show all columns\n",
    "# # pd.set_option('display.width', 1000)  # Adjust width to prevent line breaks\n",
    "# # pd.set_option('display.max_colwidth', None)  # Prevent column truncation\n",
    "# # display(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display high-level structure of data\n",
    "print(\"üìä Summary of Fisher Market Data Structure:\")\n",
    "print(\"High-level data from End of Market:\", list(end_of_market_data.keys()))\n",
    "print(\"High-level data from Fisher Market:\", list(fisher_data.keys()))\n",
    "\n",
    "# DataFrame summaries\n",
    "print(\"\\nüóÇ Fisher Market Data Overview:\")\n",
    "display(df_fisher.info())\n",
    "display(df_fisher.sample(10))\n",
    "\n",
    "print(\"\\nüóÇ After Fisher Market Data Overview:\")\n",
    "display(df_after_fisher.info())\n",
    "display(df_after_fisher.sample(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Market_Time is an integer for proper sorting\n",
    "df_fisher['Market_Time'] = df_fisher['Market_Time'].astype(int)\n",
    "\n",
    "# Split \"Good\" into \"Sector\" and \"Request_Time\"\n",
    "df_fisher[['Sector', 'Request_Time']] = df_fisher['Good'].str.split('_', expand=True)\n",
    "\n",
    "# Convert Request_Time to integer\n",
    "df_fisher['Request_Time'] = df_fisher['Request_Time'].astype(int)\n",
    "\n",
    "# Group by Sector, Request_Time, and Market_Time while counting the number of agents\n",
    "sector_request_counts = (\n",
    "    df_fisher.groupby(['Sector', 'Request_Time', 'Market_Time'])['Agent']\n",
    "    .count()\n",
    "    .reset_index()\n",
    "    .rename(columns={'Agent': 'Num_Agents'})\n",
    ")\n",
    "\n",
    "# Sort the DataFrame by Market_Time (ascending), Request_Time, and Sector (both descending)\n",
    "sector_request_counts_sorted = sector_request_counts.sort_values(\n",
    "    by=[\"Market_Time\", \"Request_Time\", \"Sector\"], ascending=[True, True, True]\n",
    ")\n",
    "\n",
    "# Display DataFrame\n",
    "pd.set_option('display.max_rows', None)\n",
    "display(sector_request_counts_sorted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Performance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_folder = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "\n",
    "file_list = [\"capacity_study/toulouse_case_cap13_updated_fisher_b-50.0_agents10_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250225_154841\",\n",
    "             \"capacity_study/toulouse_case_cap13_updated_fisher_b-50.0_agents40_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250225_154851\",\n",
    "             \"capacity_study/toulouse_case_cap13_updated_fisher_b-50.0_agents80_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250225_154921\",\n",
    "             \"capacity_study/toulouse_case_cap13_updated_fisher_b-50.0_agents120_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250225_155023\",\n",
    "             \"capacity_study/toulouse_case_cap13_updated_fisher_b-50.0_agents160_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250225_155212\",\n",
    "             \"capacity_study/toulouse_case_cap13_updated_fisher_b-50.0_agents177_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250225_155448\",\n",
    "             \"capacity_study/toulouse_case_cap10_updated_fisher_b-50.0_agents10_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250225_161400\",\n",
    "             \"capacity_study/toulouse_case_cap10_updated_fisher_b-50.0_agents40_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250225_161410\",\n",
    "             \"capacity_study/toulouse_case_cap10_updated_fisher_b-50.0_agents80_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250225_161440\",\n",
    "             \"capacity_study/toulouse_case_cap10_updated_fisher_b-50.0_agents120_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250225_161756\",\n",
    "             \"capacity_study/toulouse_case_cap10_updated_fisher_b-50.0_agents160_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250225_162731\",\n",
    "             \"capacity_study/toulouse_case_cap10_updated_fisher_b-50.0_agents177_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250225_164125\",\n",
    "             \"capacity_study/toulouse_case_cap7_updated_fisher_b-50.0_agents10_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250225_170323\",\n",
    "             \"capacity_study/toulouse_case_cap7_updated_fisher_b-50.0_agents40_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250225_170335\",\n",
    "             \"capacity_study/toulouse_case_cap7_updated_fisher_b-50.0_agents80_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250225_170543\",\n",
    "             \"capacity_study/toulouse_case_cap7_updated_fisher_b-50.0_agents120_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250225_171238\",\n",
    "            \"capacity_study/toulouse_case_cap7_updated_fisher_b-50.0_agents160_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250225_172828\",\n",
    "            \"capacity_study/toulouse_case_cap7_updated_fisher_b-50.0_agents177_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250225_210343\",\n",
    "            \"capacity_study/toulouse_case_cap4_updated_fisher_b-50.0_agents10_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250225_183540\",\n",
    "            \"capacity_study/toulouse_case_cap4_updated_fisher_b-50.0_agents40_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250225_183549\",\n",
    "            \"capacity_study/toulouse_case_cap4_updated_fisher_b-50.0_agents80_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250225_185000\",\n",
    "            \"capacity_study/toulouse_case_cap4_updated_fisher_b-50.0_agents120_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250225_191252\",\n",
    "            \"capacity_study/toulouse_case_cap4_updated_fisher_b-50.0_agents160_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250225_213948\",\n",
    "            \"capacity_study/toulouse_case_cap4_updated_fisher_b-50.0_agents177_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250225_202205\"\n",
    "\n",
    "             \n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for file in file_list:\n",
    "    folder_path = os.path.join(parent_folder, \"results\", file, \"results\")\n",
    "    csv_file_path = os.path.join(folder_path, 'market_performance_table.csv')\n",
    "    \n",
    "    try:\n",
    "        df_csv = pd.read_csv(csv_file_path)\n",
    "        df_csv[\"File\"] = file  # column to track file origin\n",
    "        capacity = int(file.split('_cap')[1].split('_')[0])\n",
    "        df_csv[\"Capacity\"] = capacity\n",
    "        df_list.append(df_csv)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {csv_file_path}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"File is empty: {csv_file_path}\")\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "pd.set_option('display.max_rows', None) \n",
    "if df_list:\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    # display(combined_df.head())\n",
    "    display(combined_df)\n",
    "else:\n",
    "    print(\"No data was loaded.\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the data\n",
    "plt.figure(figsize=(6, 6))\n",
    "# plt.title(\"Market Performance by Capacity\")\n",
    "plt.ylabel(\"Number of Iterations\")\n",
    "plt.xlabel(\"Number of Agents\")\n",
    "# plt.yticks(range(0, combined_df[\"Number_Interations\"].max() + 10, 10))\n",
    "plt.grid()\n",
    "capacities = [100,75,50,25]\n",
    "for capacity in combined_df[\"Capacity\"].unique():\n",
    "    if capacity == 13:\n",
    "        cap = 100\n",
    "    elif capacity == 10:\n",
    "        cap = 75\n",
    "    elif capacity == 7:\n",
    "        cap = 50\n",
    "    elif capacity == 4:\n",
    "        cap = 25\n",
    "    subset = combined_df[combined_df[\"Capacity\"] == capacity]\n",
    "    plt.plot(subset[\"Number_Agents\"], subset[\"Number_Interations\"], label=f\"Capacity {cap}%\", marker='o')\n",
    "\n",
    "plt.legend()\n",
    "current_dir = os.getcwd()\n",
    "plt.savefig(f\"{current_dir}/plots/nagents_niter.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(\"Market Performance by Capacity\")\n",
    "plt.ylabel(\"Number of Iterations\")\n",
    "plt.xlabel(\"Number Contested Routes\")\n",
    "plt.grid()\n",
    "for capacity in combined_df[\"Capacity\"].unique():\n",
    "    if capacity == 13:\n",
    "        cap = 100\n",
    "    elif capacity == 10:\n",
    "        cap = 75\n",
    "    elif capacity == 7:\n",
    "        cap = 50\n",
    "    elif capacity == 4:\n",
    "        cap = 25\n",
    "    subset = combined_df[combined_df[\"Capacity\"] == capacity]\n",
    "    plt.plot(subset[\"Number_Contested_Routes\"], subset[\"Number_Interations\"], label=f\"Capacity {cap}\", marker='o')\n",
    "\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the data\n",
    "plt.figure(figsize=(6, 6))\n",
    "# plt.title(\"Market Performance by Capacity\")\n",
    "plt.ylabel(\"Number of Iterations\")\n",
    "plt.xlabel(\"Runtime (seconds)\")\n",
    "plt.grid()\n",
    "for capacity in combined_df[\"Capacity\"].unique():\n",
    "    if capacity == 13:\n",
    "        cap = 100\n",
    "    elif capacity == 10:\n",
    "        cap = 75\n",
    "    elif capacity == 7:\n",
    "        cap = 50\n",
    "    elif capacity == 4:\n",
    "        cap = 25\n",
    "    subset = combined_df[combined_df[\"Capacity\"] == capacity]\n",
    "    subset = subset.sort_values(by=\"Run_Time\")\n",
    "    plt.plot(subset[\"Run_Time\"], subset[\"Number_Interations\"], label=f\"Capacity {cap}%\", marker='o')\n",
    "    # plt.plot(subset[\"Number_Interations\"], subset[\"Run_Time\"], label=f\"Capacity {cap}%\", marker='o')\n",
    "    # plt.plot(subset[\"Run_Time\"], subset[\"Number_Interations\"], label=f\"Capacity {capacity}\", marker='o')\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(f\"{current_dir}/plots/runtime_niter.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta Study\n",
    "## Reading multiple market performance files for every case adn every auction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_folder = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "new_folder_path = os.path.join(parent_folder, \"results\", \"beta_effect_MCE\")\n",
    "folder_list = [f.path for f in os.scandir(new_folder_path) if f.is_dir()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "df_method = []\n",
    "for file in folder_list:\n",
    "    folder_path = os.path.join(parent_folder, \"results\", file, \"results\")\n",
    "    csv_file_path = os.path.join(folder_path, 'market_performance_table.csv')\n",
    "    \n",
    "    try:\n",
    "        df_csv = pd.read_csv(csv_file_path)\n",
    "        df_csv[\"File\"] = file  # column to track file origin\n",
    "        match = re.search(r\"beta-method-([^\\s_]+)\", file)\n",
    "        beta_method = match.group(1) if match else \"Unknown\"\n",
    "        df_csv[\"Beta_Method\"] = beta_method  # Add beta-method as a column\n",
    "        df_list.append(df_csv)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {csv_file_path}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"File is empty: {csv_file_path}\")\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "pd.set_option('display.max_rows', None) \n",
    "\n",
    "if df_list:\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    display(combined_df)\n",
    "else:\n",
    "    print(\"No data was loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = combined_df\n",
    "\n",
    "# Filter the DataFrame based on the beta_method\n",
    "# No filtering needed, keep all methods\n",
    "# filtered_df = combined_df[combined_df[\"Beta_Method\"] == beta_method\n",
    "# Filter out the specified beta_method\n",
    "beta_method_to_avoid = \"excessdemand\"\n",
    "filtered_df = filtered_df[filtered_df[\"Beta_Method\"] != beta_method_to_avoid]\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(\"Market Auction Start Time vs Number of Iterations\")\n",
    "plt.xlabel(\"Market Auction Start Time\")\n",
    "plt.ylabel(\"Number of Iterations\")\n",
    "plt.grid(True)\n",
    "\n",
    "filtered_df = filtered_df[filtered_df[\"Market_Auction_Start_Time\"] <= 70]\n",
    "for method in filtered_df[\"Beta_Method\"].unique():\n",
    "    subset = filtered_df[filtered_df[\"Beta_Method\"] == method]\n",
    "    plt.plot(subset[\"Market_Auction_Start_Time\"], subset[\"Number_Interations\"], label=method, marker='o')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whiskers, studying tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_folder = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "new_folder_path = os.path.join(parent_folder, \"results\", \"whiskers\")\n",
    "folder_list = [f.path for f in os.scandir(new_folder_path) if f.is_dir()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "df_method = []\n",
    "for file in folder_list:\n",
    "    folder_path = os.path.join(parent_folder, \"results\", file, \"results\")\n",
    "    csv_file_path = os.path.join(folder_path, 'market_performance_table.csv')\n",
    "    \n",
    "    try:\n",
    "        df_csv = pd.read_csv(csv_file_path)\n",
    "        df_csv[\"File\"] = file  # column to track file origin\n",
    "        match = re.search(r\"alpha-([^\\s_]+)\", file)\n",
    "        alpha = match.group(1) if match else \"Unknown\"\n",
    "        df_csv[\"alpha\"] = alpha \n",
    "        df_list.append(df_csv)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {csv_file_path}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"File is empty: {csv_file_path}\")\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "pd.set_option('display.max_rows', None) \n",
    "\n",
    "if df_list:\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    display(combined_df)\n",
    "else:\n",
    "    print(\"No data was loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = combined_df\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.xlabel(\"Market Auction Start Time\")\n",
    "plt.ylabel(\"Run Time\")\n",
    "plt.grid(True)\n",
    "\n",
    "alpha_stats = filtered_df.groupby(['Market_Auction_Start_Time', 'alpha'])['Run_Time'].agg(['mean', 'max', 'min']).reset_index()\n",
    "\n",
    "for alpha_value in alpha_stats['alpha'].unique():\n",
    "    subset = alpha_stats[alpha_stats['alpha'] == alpha_value]\n",
    "    \n",
    "    yerr = np.vstack([\n",
    "        subset['mean'] - subset['min'], \n",
    "        subset['max'] - subset['mean']  \n",
    "    ])\n",
    "    \n",
    "    plt.errorbar(\n",
    "        subset['Market_Auction_Start_Time'], \n",
    "        subset['mean'], \n",
    "        yerr=yerr, \n",
    "        fmt='.', capsize=5, label=f'Alpha {alpha_value}'\n",
    "    )\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bsky",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
