{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the files with Market Iterations: These are for multiple auctions in one run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle_file(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directing to the path where the results are stored adn read all the pickle files (Market 0 to end market), extracting the market times\n",
    "# and storing the data in a list of dictionaries. The list is then converted to a DataFrame for easier visualization.\n",
    "current_dir = os.getcwd()\n",
    "parent_folder = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "folder_path = os.path.join(\n",
    "    parent_folder,\n",
    "    \"results\",\n",
    "    \"modified_bidbudget_toulouse_case3_withC_cap5_withReturn_3_highcap_fisher_b-50.0_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_receding_20250204_111131\",\n",
    "    \"results\"\n",
    ")\n",
    "\n",
    "\n",
    "fisher_files = sorted(glob.glob(os.path.join(folder_path, \"fisher_data_*.pkl\")))\n",
    "fisher_after_files = sorted(glob.glob(os.path.join(folder_path, \"fisher_data_after_*.pkl\")))\n",
    "\n",
    "# Extract the market auction time from filenames\n",
    "def extract_time(filename):\n",
    "    return int(filename.split(\"_\")[-1].split(\".\")[0])  # Extracts the number from fisher_data_X.pkl\n",
    "\n",
    "\n",
    "fisher_data_list = []\n",
    "after_fisher_data_list = []\n",
    "\n",
    "# Iterate over paired files\n",
    "for fisher_file, fisher_after_file in zip(fisher_files, fisher_after_files):\n",
    "    fisher_data = read_pickle_file(fisher_file)\n",
    "    end_of_market_data = read_pickle_file(fisher_after_file)\n",
    "\n",
    "    if fisher_data is None or end_of_market_data is None:\n",
    "        continue  # Skip if reading failed\n",
    "\n",
    "    market_time = extract_time(fisher_file)\n",
    "\n",
    "    # Extract necessary data from Fisher Market (Before Transactions)\n",
    "    prices = fisher_data[\"prices\"]\n",
    "    goods_list = fisher_data[\"goods_list\"]\n",
    "\n",
    "    # Extract necessary data from End of Market (After Transactions)\n",
    "    market_data = end_of_market_data[\"market_data\"]\n",
    "    agents_data = end_of_market_data[\"agents_data\"]\n",
    "\n",
    "    # Extract market-level data\n",
    "    end_capacities = market_data[\"capacity\"]\n",
    "    initial_capacities = market_data[\"original_capacity\"]\n",
    "    end_prices = market_data[\"prices\"]  # Prices after transactions (if they change)\n",
    "\n",
    "    print(f\"\\nüîé Processing Market Time: {market_time}\")\n",
    "    print(f\"  üìå Found {len(fisher_data['desired_goods'])} agents\")\n",
    "\n",
    "    for agent, agent_data in fisher_data[\"desired_goods\"].items():\n",
    "        desired_indx = agent_data['desired_transit_edges_idx'][0]  # Directly access\n",
    "\n",
    "        try:\n",
    "            # Data before transactions (Fisher Market)\n",
    "            fisher_data_list.append({\n",
    "                \"Market_Time\": market_time,\n",
    "                \"Agent\": agent,\n",
    "                \"Edge_Index\": desired_indx,\n",
    "                \"Price\": prices[desired_indx],  # Price before transaction\n",
    "                \"Initial_Capacity\": initial_capacities[desired_indx],  # Starting capacity\n",
    "                \"Good\": goods_list[desired_indx][1],\n",
    "                \"Data_Type\": \"Fisher\"\n",
    "            })\n",
    "\n",
    "            # Extract agent-specific information after the market transaction\n",
    "            agent_final_allocation = agents_data[agent].get(\"final_allocation\", {})\n",
    "            agent_payment = agents_data[agent].get(\"payment\", 0)\n",
    "            agent_valuation = agents_data[agent].get(\"valuation\", {})\n",
    "\n",
    "            # Data after transactions (After Fisher Market)\n",
    "            after_fisher_data_list.append({\n",
    "                \"Market_Time\": market_time,\n",
    "                \"Agent\": agent,\n",
    "                \"Edge_Index\": desired_indx,\n",
    "                \"Price\": end_prices[desired_indx],  # Final price after auction\n",
    "                \"End_Capacity\": end_capacities[desired_indx],  # Capacity after auction\n",
    "                \"Good\": goods_list[desired_indx][1],\n",
    "                \"Final_Goods_allocated\": agents_data[agent][\"agent_goods_list\"],  # Final goods allocated\n",
    "                \"Final_goods_vector\": agent_final_allocation,\n",
    "                \"Payment\": agent_payment,\n",
    "                \"Data_Type\": \"After_Fisher\"\n",
    "            })\n",
    "        except KeyError as e:\n",
    "            print(f\"    ‚ùå Skipping {agent}: Key {e} not found in dataset!\")\n",
    "\n",
    "# Create DataFrames\n",
    "df_fisher = pd.DataFrame(fisher_data_list)\n",
    "df_after_fisher = pd.DataFrame(after_fisher_data_list)\n",
    "\n",
    "# ## uncomment below if you want to see the entire dataframe\n",
    "# # pd.set_option('display.max_rows', None)  # Show all rows\n",
    "# # pd.set_option('display.max_columns', None)  # Show all columns\n",
    "# # pd.set_option('display.width', 1000)  # Adjust width to prevent line breaks\n",
    "# # pd.set_option('display.max_colwidth', None)  # Prevent column truncation\n",
    "# # display(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display high-level structure of data\n",
    "print(\"üìä Summary of Fisher Market Data Structure:\")\n",
    "print(\"High-level data from End of Market:\", list(end_of_market_data.keys()))\n",
    "print(\"High-level data from Fisher Market:\", list(fisher_data.keys()))\n",
    "\n",
    "# DataFrame summaries\n",
    "print(\"\\nüóÇ Fisher Market Data Overview:\")\n",
    "display(df_fisher.info())\n",
    "display(df_fisher.sample(10))\n",
    "\n",
    "print(\"\\nüóÇ After Fisher Market Data Overview:\")\n",
    "display(df_after_fisher.info())\n",
    "display(df_after_fisher.sample(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Market_Time is an integer for proper sorting\n",
    "df_fisher['Market_Time'] = df_fisher['Market_Time'].astype(int)\n",
    "\n",
    "# Split \"Good\" into \"Sector\" and \"Request_Time\"\n",
    "df_fisher[['Sector', 'Request_Time']] = df_fisher['Good'].str.split('_', expand=True)\n",
    "\n",
    "# Convert Request_Time to integer\n",
    "df_fisher['Request_Time'] = df_fisher['Request_Time'].astype(int)\n",
    "\n",
    "# Group by Sector, Request_Time, and Market_Time while counting the number of agents\n",
    "sector_request_counts = (\n",
    "    df_fisher.groupby(['Sector', 'Request_Time', 'Market_Time'])['Agent']\n",
    "    .count()\n",
    "    .reset_index()\n",
    "    .rename(columns={'Agent': 'Num_Agents'})\n",
    ")\n",
    "\n",
    "# Sort the DataFrame by Market_Time (ascending), Request_Time, and Sector (both descending)\n",
    "sector_request_counts_sorted = sector_request_counts.sort_values(\n",
    "    by=[\"Market_Time\", \"Request_Time\", \"Sector\"], ascending=[True, True, True]\n",
    ")\n",
    "\n",
    "# Display DataFrame\n",
    "pd.set_option('display.max_rows', None)\n",
    "display(sector_request_counts_sorted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Performance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_folder = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "new_folder_path = os.path.join(parent_folder, \"results\", \"capacity_study\")\n",
    "file_list = [f.path for f in os.scandir(new_folder_path) if f.is_dir()]\n",
    "\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for file in file_list:\n",
    "    folder_path = os.path.join(parent_folder, \"results\", file, \"results\")\n",
    "    csv_file_path = os.path.join(folder_path, 'market_performance_table.csv')\n",
    "    \n",
    "    try:\n",
    "        df_csv = pd.read_csv(csv_file_path)\n",
    "        df_csv[\"File\"] = file  # column to track file origin\n",
    "        capacity = int(file.split('_cap')[1].split('_')[0])\n",
    "        df_csv[\"Capacity\"] = capacity\n",
    "        df_list.append(df_csv)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {csv_file_path}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"File is empty: {csv_file_path}\")\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "\n",
    "pd.set_option('display.max_rows', None) \n",
    "if df_list:\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    combined_df = combined_df.sort_values(by=[\"Capacity\", \"Number_Agents\"])\n",
    "    # display(combined_df.head())\n",
    "    display(combined_df)\n",
    "else:\n",
    "    print(\"No data was loaded.\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the data\n",
    "plt.figure(figsize=(6, 6))\n",
    "# plt.title(\"Market Performance by Capacity\")\n",
    "plt.ylabel(\"Number of Iterations\", fontsize=12)\n",
    "plt.xlabel(\"Number of Agents\", fontsize=12)\n",
    "# plt.yticks(range(0, combined_df[\"Number_Interations\"].max() + 10, 10))\n",
    "plt.grid()\n",
    "capacities = [100,75,50,25]\n",
    "combined_df = combined_df.sort_values(by=[\"Number_Agents\", \"Capacity\"])\n",
    "\n",
    "colors = {14: 'blue', 10: 'green', 7: 'orange', 4: 'red'}\n",
    "# combined_df = combined_df.sort_values(by=\"Capacity\")\n",
    "for capacity in combined_df[\"Capacity\"].unique():\n",
    "    if capacity == 14:\n",
    "        cap = 100\n",
    "    elif capacity == 10:\n",
    "        cap = 75\n",
    "    elif capacity == 7:\n",
    "        cap = 50\n",
    "    elif capacity == 4:\n",
    "        cap = 25\n",
    "    subset = combined_df[combined_df[\"Capacity\"] == capacity]\n",
    "    plt.plot(subset[\"Number_Agents\"], subset[\"Number_Interations\"], label=f\"Capacity {cap}%\", marker='o', color=colors[capacity])\n",
    "\n",
    "plt.legend()\n",
    "current_dir = os.getcwd()\n",
    "plt.savefig(f\"{current_dir}/plots/nagents_niter.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(\"Market Performance by Capacity\")\n",
    "plt.ylabel(\"Number of Iterations\")\n",
    "plt.xlabel(\"Number Contested Routes\")\n",
    "plt.grid()\n",
    "for capacity in combined_df[\"Capacity\"].unique():\n",
    "    if capacity == 14:\n",
    "        cap = 100\n",
    "    elif capacity == 10:\n",
    "        cap = 75\n",
    "    elif capacity == 7:\n",
    "        cap = 50\n",
    "    elif capacity == 4:\n",
    "        cap = 25\n",
    "    subset = combined_df[combined_df[\"Capacity\"] == capacity]\n",
    "    plt.plot(subset[\"Number_Contested_Routes\"], subset[\"Number_Interations\"], label=f\"Capacity {cap}\", marker='o')\n",
    "\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the data\n",
    "plt.figure(figsize=(6, 6))\n",
    "# plt.title(\"Market Performance by Capacity\")\n",
    "plt.ylabel(\"Number of Iterations\")\n",
    "plt.xlabel(\"Runtime (seconds)\")\n",
    "plt.grid()\n",
    "for capacity in combined_df[\"Capacity\"].unique():\n",
    "    if capacity == 13:\n",
    "        cap = 100\n",
    "    elif capacity == 10:\n",
    "        cap = 75\n",
    "    elif capacity == 7:\n",
    "        cap = 50\n",
    "    elif capacity == 4:\n",
    "        cap = 25\n",
    "    subset = combined_df[combined_df[\"Capacity\"] == capacity]\n",
    "    subset = subset.sort_values(by=\"Run_Time\")\n",
    "    plt.plot(subset[\"Run_Time\"], subset[\"Number_Interations\"], label=f\"Capacity {cap}%\", marker='o')\n",
    "    # plt.plot(subset[\"Number_Interations\"], subset[\"Run_Time\"], label=f\"Capacity {cap}%\", marker='o')\n",
    "    # plt.plot(subset[\"Run_Time\"], subset[\"Number_Interations\"], label=f\"Capacity {capacity}\", marker='o')\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(f\"{current_dir}/plots/runtime_niter.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta Study\n",
    "## Reading multiple market performance files for every case adn every auction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_folder = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "new_folder_path = os.path.join(parent_folder, \"results\", \"fixed_pt_error\")\n",
    "folder_list = [f.path for f in os.scandir(new_folder_path) if f.is_dir()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "df_method = []\n",
    "for file in folder_list:\n",
    "    folder_path = os.path.join(parent_folder, \"results\", file, \"results\")\n",
    "    csv_file_path = os.path.join(folder_path, 'market_performance_table.csv')\n",
    "    results_table_path = os.path.join(new_folder_path, \"market_results_table.csv\")\n",
    "    \n",
    "    try:\n",
    "        df_csv = pd.read_csv(csv_file_path)\n",
    "        df_csv[\"File\"] = file  # column to track file origin\n",
    "        match = re.search(r\"beta-method-([^\\s_]+)\", file)\n",
    "        beta_method = match.group(1) if match else \"Unknown\"\n",
    "        df_csv[\"Beta_Method\"] = beta_method  # Add beta-method as a column\n",
    "        df_list.append(df_csv)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {csv_file_path}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"File is empty: {csv_file_path}\")\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "pd.set_option('display.max_rows', None) \n",
    "\n",
    "if df_list:\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    display(combined_df)\n",
    "else:\n",
    "    print(\"No data was loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = combined_df\n",
    "\n",
    "# Filter the DataFrame based on the beta_method\n",
    "# No filtering needed, keep all methods\n",
    "# filtered_df = combined_df[combined_df[\"Beta_Method\"] == beta_method\n",
    "# Filter out the specified beta_method\n",
    "# beta_method_to_avoid = \"excessdemand\"\n",
    "# filtered_df = filtered_df[filtered_df[\"Beta_Method\"] != beta_method_to_avoid]\n",
    "# filtered_df = filtered_df[filtered_df[\"Beta_Method\"] == 'none']\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(\"Market Auction Start Time vs Number of Iterations\")\n",
    "plt.xlabel(\"Market Auction Start Time\")\n",
    "plt.ylabel(\"Number of Iterations\")\n",
    "plt.grid(True)\n",
    "\n",
    "# filtered_df = filtered_df[filtered_df[\"Market_Auction_Start_Time\"] <= 70]\n",
    "for method in filtered_df[\"Beta_Method\"].unique():\n",
    "    subset = filtered_df[filtered_df[\"Beta_Method\"] == method]\n",
    "    plt.plot(subset[\"Market_Auction_Start_Time\"], subset[\"Number_Interations\"], label=method, marker='o')\n",
    "\n",
    "plt.legend()\n",
    "# plt.show()\n",
    "plt.savefig(f\"{current_dir}/plots/beta_method_niter.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha, studying tolerance (whisker plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_folder = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "new_folder_path = os.path.join(parent_folder, \"results\", \"alpha_study\")\n",
    "folder_list = [f.path for f in os.scandir(new_folder_path) if f.is_dir()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "df_method = []\n",
    "for file in folder_list:\n",
    "    folder_path = os.path.join(parent_folder, \"results\", file, \"results\")\n",
    "    csv_file_path = os.path.join(folder_path, 'market_performance_table.csv')\n",
    "    \n",
    "    try:\n",
    "        df_csv = pd.read_csv(csv_file_path)\n",
    "        df_csv[\"File\"] = file  # column to track file origin\n",
    "        match = re.search(r\"alpha-([^\\s_]+)\", file)\n",
    "        alpha = match.group(1) if match else \"Unknown\"\n",
    "        df_csv[\"alpha\"] = alpha \n",
    "        df_list.append(df_csv)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {csv_file_path}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"File is empty: {csv_file_path}\")\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "pd.set_option('display.max_rows', None) \n",
    "\n",
    "if df_list:\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    display(combined_df)\n",
    "else:\n",
    "    print(\"No data was loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = combined_df\n",
    "filtered_df['alpha'] = filtered_df['alpha'].astype(float)\n",
    "\n",
    "alpha_values = sorted(filtered_df['alpha'].unique())\n",
    "data = [filtered_df[filtered_df['alpha'] == alpha]['Number_Interations'].values for alpha in alpha_values]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "# plt.boxplot(data, positions=alpha_values, widths=0.1, patch_artist=True)\n",
    "meanprops = dict(markeredgecolor='red', markersize=10, linestyle='-', linewidth=2, color='red')\n",
    "plt.boxplot(data, positions=alpha_values, widths=0.25, showfliers=False, patch_artist=True,\n",
    "            boxprops=dict(facecolor='lightblue', color='blue'),\n",
    "            capprops=dict(color='blue'),\n",
    "            whiskerprops=dict(color='blue'),\n",
    "            flierprops=dict(color='blue', markeredgecolor='blue'),\n",
    "            medianprops=meanprops)\n",
    "\n",
    "\n",
    "# plt.boxplot(data, positions=alpha_values, widths= 0.25,  showfliers=False)\n",
    "# Set x-axis ticks to match actual alpha values\n",
    "# plt.xticks(alpha_values, labels=[str(alpha) for alpha in alpha_values])\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(r'Tolerance $\\alpha$', fontsize=12)\n",
    "plt.ylabel(\"Number of Iterations\", fontsize=12)\n",
    "# plt.xscale(\"log\")  \n",
    "plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)  # Grid for better visualization\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(f\"{current_dir}/plots/alpha_niter_boxplot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lamba Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_folder = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "new_folder_path = os.path.join(parent_folder, \"results\", \"InnerLoop_freq_study\")\n",
    "folder_list = [f.path for f in os.scandir(new_folder_path) if f.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "df_method = []\n",
    "for file in folder_list:\n",
    "    folder_path = os.path.join(parent_folder, \"results\", file, \"results\")\n",
    "    csv_file_path = os.path.join(folder_path, 'market_performance_table.csv')\n",
    "    \n",
    "    try:\n",
    "        df_csv = pd.read_csv(csv_file_path)\n",
    "        df_csv[\"File\"] = file  # column to track file origin\n",
    "        match = re.search(r\"freq([^\\s_]+)\", file)\n",
    "        lambda_val = match.group(1) if match else \"Unknown\"\n",
    "        df_csv[\"Freq\"] = lambda_val\n",
    "        df_list.append(df_csv)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {csv_file_path}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"File is empty: {csv_file_path}\")\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "pd.set_option('display.max_rows', None) \n",
    "\n",
    "if df_list:\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    display(combined_df)\n",
    "else:\n",
    "    print(\"No data was loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = combined_df\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "plt.xlabel(\"Frequency of Inner Loop Update (N)\", fontsize=12)\n",
    "plt.ylabel(\"Number of Iterations\", fontsize=12)\n",
    "plt.grid(True)\n",
    "filtered_df = filtered_df.sort_values(by=\"Freq\", key=lambda x: x.astype(float))\n",
    "\n",
    "plt.plot(filtered_df[\"Freq\"], filtered_df[\"Number_Interations\"], marker='o')\n",
    "\n",
    "# plt.show()\n",
    "plt.savefig(f\"{current_dir}/plots/lambda_niter.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percent/Number of drop-out vs Number of agents. \n",
    "### Read from result files the status of allocated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_folder = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "new_folder_path = os.path.join(parent_folder, \"results\", \"capacity_study\")\n",
    "folder_list = [f.path for f in os.scandir(new_folder_path) if f.is_dir()]\n",
    "print(folder_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary_data = {}\n",
    "\n",
    "for folder in folder_list:\n",
    "    # Construct the new folder path\n",
    "    new_folder_path = os.path.join(folder, \"results\")\n",
    "    results_table_path = os.path.join(new_folder_path, \"market_results_table.csv\")\n",
    "    performance_table_path = os.path.join(new_folder_path, \"market_performance_table.csv\")\n",
    "    \n",
    "    try:\n",
    "        df_results = pd.read_csv(results_table_path)\n",
    "        df_performance = pd.read_csv(performance_table_path)\n",
    "        \n",
    "        # Extract the capacity value from the folder name\n",
    "        capacity = int(folder.split('_cap')[1].split('_')[0])\n",
    "        \n",
    "        # Count each unique value under the column 'Status'\n",
    "        status_counts = df_results['Status'].value_counts().to_dict()\n",
    "        \n",
    "        # Get the number of agents\n",
    "        num_agents = df_performance['Number_Agents'].iloc[0]\n",
    "        \n",
    "        # Prepare column names specific to this file\n",
    "        file_key = f\"{folder}_cap{capacity}\"\n",
    "        \n",
    "        # Store data in a dictionary format\n",
    "        summary_data[file_key] = {\n",
    "            'Capacity': capacity,\n",
    "            'Number_Agents': num_agents,\n",
    "            'Allocated': status_counts.get('allocated', 0),\n",
    "            'Delayed': status_counts.get('delayed', 0),\n",
    "            'Dropped': status_counts.get('dropped', 0),\n",
    "            'Rebased': status_counts.get('rebased', 0),\n",
    "            \"Parked\": status_counts.get('parked', 0)\n",
    "        }\n",
    "        \n",
    "        # Add unknown status categories dynamically\n",
    "        for status, count in status_counts.items():\n",
    "            if status not in [\"allocated\", \"delayed\", \"dropped\", \"rebased\", \"parked\"]:\n",
    "                summary_data[file_key][f\"Unknown_{status}\"] = count\n",
    "                \n",
    "        summary_data[file_key]['Check'] = (\n",
    "            summary_data[file_key]['Allocated'] +\n",
    "            summary_data[file_key]['Delayed'] +\n",
    "            summary_data[file_key]['Dropped'] +\n",
    "            summary_data[file_key]['Rebased'] +\n",
    "            summary_data[file_key]['Parked'] == num_agents\n",
    "        )\n",
    "        \n",
    "        summary_data[file_key][\"Percentage_Allocated\"] = summary_data[file_key][\"Allocated\"] / num_agents * 100\n",
    "        summary_data[file_key][\"Percentage_Delayed\"] = summary_data[file_key][\"Delayed\"] / num_agents * 100\n",
    "        summary_data[file_key][\"Percentage_Dropped\"] = summary_data[file_key][\"Dropped\"] / num_agents * 100\n",
    "        summary_data[file_key][\"Percentage_Rebased\"] = summary_data[file_key][\"Rebased\"] / num_agents * 100\n",
    "        summary_data[file_key][\"Percentage_Parked\"] = summary_data[file_key][\"Parked\"] / num_agents * 100\n",
    "        summary_data[file_key][\"perfect_dropped_rebased\"] = (summary_data[file_key][\"Dropped\"] + summary_data[file_key][\"Rebased\"]) / num_agents * 100\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File not found: {e}\")\n",
    "    except pd.errors.EmptyDataError as e:\n",
    "        print(f\"File is empty: {e}\")\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "if summary_data:\n",
    "    df_status_summary = pd.DataFrame.from_dict(summary_data, orient='index')\n",
    "    df_status_summary.fillna(0, inplace=True)\n",
    "    display(df_status_summary)\n",
    "else:\n",
    "    print(\"No valid data collected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the percent of dropped/rebased vs number of agents\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.xlabel(\"Number of Agents\", fontsize=12)\n",
    "plt.ylabel(\"Percent of Unallocated Agents %\", fontsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot each capacity\n",
    "\n",
    "colors = {14: 'blue', 10: 'green', 7: 'orange', 4: 'red'}\n",
    "\n",
    "df_status_summary = df_status_summary.sort_values(by=['Capacity', 'Number_Agents'])\n",
    "\n",
    "for capacity in df_status_summary['Capacity'].unique():\n",
    "    if capacity == 14:\n",
    "        cap = 100\n",
    "    elif capacity == 10:\n",
    "        cap = 75\n",
    "    elif capacity == 7:\n",
    "        cap = 50\n",
    "    elif capacity == 4:\n",
    "        cap = 25\n",
    "    subset = df_status_summary[df_status_summary['Capacity'] == capacity]\n",
    "    # plt.plot(subset['Number_Agents'], subset['Percentage_Dropped'], label=f\"Capacity {cap}%\", marker='o', color=colors[capacity])\n",
    "    # plt.plot(subset['Number_Agents'], subset['Percentage_Rebased'], label=f\"Capacity {cap}%\", marker='o', color=colors[capacity])\n",
    "    # plt.plot(subset['Number_Agents'], subset['Percentage_Allocated'], label=f\"Capacity {cap} Allocated\", marker='s', color=colors[capacity])\n",
    "    # plt.plot(subset['Number_Agents'], subset['Percentage_Delayed'], label=f\"Capacity {cap} Delayed\", marker='d', color=colors[capacity])\n",
    "    plt.plot(subset['Number_Agents'], subset['Percentage_Rebased'], label=f\"Capacity {cap}%\", marker='o', color=colors[capacity])\n",
    "\n",
    "plt.legend()\n",
    "# plt.show()\n",
    "plt.savefig(f\"{current_dir}/plots/capacity_study_percentDropped.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage of Drops, parked, rebased, delayed in Beta Study, per auction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_folder = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "new_folder_path = os.path.join(parent_folder, \"results\", \"fixed_pt_error\")\n",
    "folder_list = [f.path for f in os.scandir(new_folder_path) if f.is_dir()]\n",
    "print(folder_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data = []\n",
    "\n",
    "for folder in folder_list:\n",
    "    # Path containing the CSV files\n",
    "    results_path = os.path.join(folder, \"results\")\n",
    "    performance_table_path = os.path.join(results_path, \"market_performance_table.csv\")\n",
    "\n",
    "    # Read performance table for the number of agents\n",
    "    try:\n",
    "        df_performance = pd.read_csv(performance_table_path)\n",
    "        num_agents = df_performance['Number_Agents'].iloc[0]\n",
    "    except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        num_agents = None\n",
    "\n",
    "    if os.path.isdir(results_path):\n",
    "        for file in os.listdir(results_path):\n",
    "            # Match files named \"results_table_XXX.csv\"\n",
    "            match_auction = re.match(r\"results_table_(\\d+)\\.csv\", file)\n",
    "            if match_auction:\n",
    "                auction_start_time = int(match_auction.group(1))\n",
    "                csv_file_path = os.path.join(results_path, file)\n",
    "\n",
    "                try:\n",
    "                    df_results = pd.read_csv(csv_file_path)\n",
    "                except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "                    continue\n",
    "\n",
    "                # Extract beta method from file name\n",
    "                match_beta = re.search(r\"beta-method-([^\\s_]+)\", folder)\n",
    "                beta_method = match_beta.group(1) if match_beta else \"Unknown\"\n",
    "\n",
    "                # Count status occurrences\n",
    "                if 'Status' in df_results.columns:\n",
    "                    status_counts = df_results['Status'].value_counts().to_dict()\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                # Store the results in a list of dictionaries\n",
    "                summary_data.append({\n",
    "                    'Beta_Method': beta_method,\n",
    "                    'Auction_Start_Time': auction_start_time,\n",
    "                    'Number_Agents': num_agents if num_agents else 0,\n",
    "                    'Allocated': status_counts.get('allocated', 0),\n",
    "                    'Delayed': status_counts.get('delayed', 0),\n",
    "                    'Dropped': status_counts.get('dropped', 0),\n",
    "                    'Rebased': status_counts.get('rebased', 0),\n",
    "                    'Parked': status_counts.get('parked', 0)\n",
    "                })\n",
    "\n",
    "# Convert list of dictionaries to DataFrame\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "\n",
    "# df_summary = df_summary[df_summary[\"Auction_Start_Time\"] <= 70]\n",
    "if df_summary.empty:\n",
    "    print(\"No valid data collected.\")\n",
    "else:\n",
    "    print(\"\\nAggregated Data:\")\n",
    "    display(df_summary)\n",
    "\n",
    "    # Filter out specific beta methods if needed\n",
    "    beta_method_to_avoid = \"excessdemand\"\n",
    "    df_filtered = df_summary[df_summary[\"Beta_Method\"] != beta_method_to_avoid]\n",
    "\n",
    "    # -----------------------\n",
    "    # Bar Plot: \"Dropped\" vs Auction Start Time\n",
    "    # -----------------------\n",
    "    # pivot_dropped = df_filtered.pivot(index=\"Auction_Start_Time\", columns=\"Beta_Method\", values=\"Dropped\")\n",
    "    # pivot_dropped.plot(kind='bar', figsize=(12, 6), width=0.8)\n",
    "    # plt.title(\"Dropped Requests by Auction Start Time and Beta Method\")\n",
    "    # plt.xlabel(\"Auction Start Time\")\n",
    "    # plt.ylabel(\"Number of Dropped Requests\")\n",
    "    # plt.grid(axis='y')\n",
    "    # plt.legend(title=\"Beta Method\")\n",
    "    # plt.xticks(rotation=45)\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig(f\"{current_dir}/plots/dropped_by_beta_method.png\")\n",
    "    # plt.show()\n",
    "\n",
    "    # -----------------------\n",
    "    # Bar Plot: \"Allocated\" vs Auction Start Time\n",
    "    # -----------------------\n",
    "    pivot_allocated = df_filtered.pivot(index=\"Auction_Start_Time\", columns=\"Beta_Method\", values=\"Allocated\")\n",
    "    pivot_allocated.plot(kind='bar', figsize=(12, 6), width=0.8)\n",
    "    plt.title(\"Allocated Requests by Auction Start Time and Beta Method\")\n",
    "    plt.xlabel(\"Auction Start Time\")\n",
    "    plt.ylabel(\"Number of Allocated Requests\")\n",
    "    plt.grid(axis='y')\n",
    "    plt.legend(title=\"Beta Method\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{current_dir}/plots/allocated_by_beta_method.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # -----------------------\n",
    "    # Bar Plot: \"Delayed\" vs Auction Start Time\n",
    "    # -----------------------\n",
    "    pivot_delayed = df_filtered.pivot(index=\"Auction_Start_Time\", columns=\"Beta_Method\", values=\"Delayed\")\n",
    "    pivot_delayed.plot(kind='bar', figsize=(12, 6), width=0.8)\n",
    "    plt.title(\"Delayed Requests by Auction Start Time and Beta Method\")\n",
    "    plt.xlabel(\"Auction Start Time\")\n",
    "    plt.ylabel(\"Number of Delayed Requests\")\n",
    "    plt.grid(axis='y')\n",
    "    plt.legend(title=\"Beta Method\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{current_dir}/plots/delayed_by_beta_method.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # -----------------------\n",
    "    # Bar Plot: \"Rebased\" vs Auction Start Time\n",
    "    # -----------------------\n",
    "    pivot_rebased = df_filtered.pivot(index=\"Auction_Start_Time\", columns=\"Beta_Method\", values=\"Rebased\")\n",
    "    pivot_rebased.plot(kind='bar', figsize=(12, 6), width=0.8)\n",
    "    plt.title(\"Rebased Requests by Auction Start Time and Beta Method\")\n",
    "    plt.xlabel(\"Auction Start Time\")\n",
    "    plt.ylabel(\"Number of Rebased Requests\")\n",
    "    plt.grid(axis='y')\n",
    "    plt.legend(title=\"Beta Method\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{current_dir}/plots/rebased_by_beta_method.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading plot data from the constraitns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "def extract_file_number(filename):\n",
    "    match = re.search(r\"fisher_data_(\\d+)\\.pkl\", filename)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "# Settings\n",
    "x_y_constraint_threshold = 0.1\n",
    "linearity_constraint_threshold = 0.01\n",
    "TOL_ERROR = 1e-3\n",
    "\n",
    "# Root directory\n",
    "current_dir = os.getcwd()\n",
    "parent_folder = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "study_folder = os.path.join(parent_folder, \"results\", \"fixed_pt_error\")\n",
    "\n",
    "# Find all subdirectories (beta methods)\n",
    "all_run_folders = [f.path for f in os.scandir(study_folder) if f.is_dir()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_time_to_files = defaultdict(list)\n",
    "\n",
    "for run_folder in all_run_folders:\n",
    "    run_results_folder = os.path.join(run_folder, \"results\")\n",
    "    all_files = glob.glob(os.path.join(run_results_folder, \"fisher_data_*.pkl\"))\n",
    "\n",
    "    for f in all_files:\n",
    "        market_time = extract_file_number(f)\n",
    "        if market_time is not None:\n",
    "            market_time_to_files[market_time].append(f)\n",
    "\n",
    "# Now process each market auction time\n",
    "for market_time, files in market_time_to_files.items():\n",
    "    files.sort()  # Not strictly necessary but good for consistency\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(f\"Market Clearing Error vs Iteration (Market Time {market_time})\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Market Clearing Error\")\n",
    "\n",
    "    for fisher_file in files:\n",
    "        try:\n",
    "            folder_name = fisher_file.split(os.sep)[-3]\n",
    "            beta_match = re.search(r\"beta-method-([^\\s_]+)\", folder_name)\n",
    "            beta = beta_match.group(1) if beta_match else \"unknown\"\n",
    "\n",
    "            with open(fisher_file, 'rb') as file:\n",
    "                data = pickle.load(file)\n",
    "\n",
    "            data_to_plot = data.get(\"data_to_plot\", {})\n",
    "            abs_error = data_to_plot.get(\"abs_error\", [])\n",
    "            error = data_to_plot.get(\"error\", [])\n",
    "            x_iter = data_to_plot.get(\"x_iter\", 0)\n",
    "            market_clearing = data_to_plot.get(\"market_clearing\", [])\n",
    "            p = data_to_plot.get(\"p\", [])\n",
    "\n",
    "\n",
    "            num_agents = len(abs_error)\n",
    "            supply_size = len(p)  # includes default + dropout\n",
    "            supply_length = supply_size - 2\n",
    "            tolerance = num_agents * np.sqrt(supply_length) * TOL_ERROR\n",
    "            x_range = range(1, len(market_clearing) + 1)\n",
    "\n",
    "            plt.plot(x_range, market_clearing, label=f\"{beta}\")\n",
    "            plt.axhline(y=tolerance, color='r', linestyle='--', linewidth=1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {fisher_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    fig_name = f\"MC_error_market_time_{market_time}.png\"\n",
    "    plt.savefig(os.path.join(study_folder, fig_name))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for fisher_file in files:\n",
    "        try:\n",
    "            folder_name = fisher_file.split(os.sep)[-3]\n",
    "            beta_match = re.search(r\"beta-method-([^\\s_]+)\", folder_name)\n",
    "            beta = beta_match.group(1) if beta_match else \"unknown\"\n",
    "\n",
    "            with open(fisher_file, 'rb') as file:\n",
    "                data = pickle.load(file)\n",
    "\n",
    "            data_to_plot = data.get(\"data_to_plot\", {})\n",
    "            error = data_to_plot.get(\"error\", [])\n",
    "            x_iter = data_to_plot.get(\"x_iter\", 0)\n",
    "\n",
    "\n",
    "            x_range = range(1, x_iter + 1)\n",
    "            max_constraint_error = [max(errs[i] for errs in error) for i in range(x_iter)]\n",
    "            plt.plot(x_range, max_constraint_error, label=f\"{beta}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {fisher_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "    plt.axhline(y=linearity_constraint_threshold, color='r', linestyle='--', linewidth=1)\n",
    "    plt.ylabel('Constraint Error (max ||Ax - b||‚àû)')\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Linearity Constraint Error (Market Time {market_time})\")\n",
    "    fig_name = f\"linear_constraint_market_time_{market_time}.png\"\n",
    "    plt.savefig(os.path.join(study_folder, fig_name))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for fisher_file in files:\n",
    "        try:\n",
    "            folder_name = fisher_file.split(os.sep)[-3]\n",
    "            beta_match = re.search(r\"beta-method-([^\\s_]+)\", folder_name)\n",
    "            beta = beta_match.group(1) if beta_match else \"unknown\"\n",
    "\n",
    "            with open(fisher_file, 'rb') as file:\n",
    "                data = pickle.load(file)\n",
    "\n",
    "            data_to_plot = data.get(\"data_to_plot\", {})\n",
    "            abs_error = data_to_plot.get(\"abs_error\", [])\n",
    "            x_iter = data_to_plot.get(\"x_iter\", 0)\n",
    "\n",
    "\n",
    "            x_range = range(1, x_iter + 1)\n",
    "            max_x_y_error = [max(errs[i] for errs in abs_error) for i in range(x_iter)]\n",
    "            plt.plot(x_range, max_x_y_error, label=f\"{beta}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {fisher_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "    plt.axhline(y=x_y_constraint_threshold, color='r', linestyle='--', linewidth=1)\n",
    "    plt.ylabel('Constraint Error (max ||x - y||‚àû)')\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"x - y Constraint Error (Market Time {market_time})\")\n",
    "    fig_name = f\"x_y_constraint_market_time_{market_time}.png\"\n",
    "    plt.savefig(os.path.join(study_folder, fig_name))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for fisher_file in files:\n",
    "        try:\n",
    "            folder_name = fisher_file.split(os.sep)[-3]\n",
    "            beta_match = re.search(r\"beta-method-([^\\s_]+)\", folder_name)\n",
    "            beta = beta_match.group(1) if beta_match else \"unknown\"\n",
    "\n",
    "            with open(fisher_file, 'rb') as file:\n",
    "                data = pickle.load(file)\n",
    "\n",
    "            data_to_plot = data.get(\"data_to_plot\", {})\n",
    "            fixed_point_error = data_to_plot.get(\"fixed_point_error\", [])\n",
    "            x_iter = data_to_plot.get(\"x_iter\", 0)\n",
    "\n",
    "\n",
    "            x_range = range(1, x_iter + 1)\n",
    "            # max_x_y_error = [max(errs[i] for errs in fixed_point_error) for i in range(x_iter)]\n",
    "            plt.plot(x_range, fixed_point_error, label=f\"{beta}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {fisher_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # plt.axhline(y=x_y_constraint_threshold, color='r', linestyle='--', linewidth=1)\n",
    "    plt.ylabel('Fixed Point Error (||\\lambda - \\omega||)')\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Fixed  point Error (Market Time {market_time})\")\n",
    "    fig_name = f\"fixed_point_error_market_time_{market_time}.png\"\n",
    "    plt.savefig(os.path.join(study_folder, fig_name))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bsky",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
