{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"results/final_runs/toulouse_case_cap7_updated_20_fisher_b-50.0_agentsall_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_beta-method-none_alpha-1.0_use_AADMM-False_receding_20250409_100318/results/\"\n",
    "# Original case: # folder_path = \"results/final_runs/toulouse_case_cap7_updated_20_fisher_b-50.0_agentsall_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_beta-method-none_alpha-1.0_receding_20250304_095807/results/\"\n",
    "pattern = re.compile(r'^results_table_\\d+\\.csv$')\n",
    "file_list = [f for f in os.listdir(folder_path) if pattern.match(f)]\n",
    "auction_times = [int(file.split('_')[2][:-4]) + 20 for file in file_list]\n",
    "sorted_auction_times = np.sort(auction_times)\n",
    "sorted_file_list = [f for _, f in sorted(zip(auction_times, file_list))]\n",
    "summary_data = {}\n",
    "\n",
    "starting_capacity_list, capacity_list, prices_list, goods_list = [], [], [], []\n",
    "\n",
    "path_list = [os.path.join(folder_path, file) for file in sorted_file_list]\n",
    "df_list = [pd.read_csv(path) for path in path_list]\n",
    "\n",
    "ind = 0\n",
    "rebases_per_agent = {}\n",
    "delay_vals = []\n",
    "for df_results, auction_time, file_name in zip(df_list, sorted_auction_times, sorted_file_list):\n",
    "\n",
    "    auction_number = int(auction_time/20)\n",
    "    # Construct the new folder path\n",
    "    # new_folder_path = os.path.join(file, \"results\")\n",
    "    # results_table_path = os.path.join(new_folder_path, \"market_results_table.csv\")\n",
    "    # performance_table_path = os.path.join(new_folder_path, \"market_performance_table.csv\")\n",
    "    # auction_time = int(file.split('_')[2][:-4])\n",
    "\n",
    "    # results_table_path = os.path.join(folder_path, file)\n",
    "    pickle_file = os.path.join(folder_path, f\"fisher_data_after_{auction_time - 20}.pkl\")\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    pickle_file = os.path.join(folder_path, f\"fisher_data_{auction_time - 20}.pkl\")\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        fisher_data = pickle.load(f)\n",
    "    \n",
    "    starting_capacity_list.append(fisher_data['capacity'])\n",
    "    capacity_list.append(data[\"market_data\"]['capacity'])\n",
    "    prices_list.append(data[\"market_data\"]['prices'])\n",
    "    goods_list.append(data[\"market_data\"]['goods_list'])\n",
    "\n",
    "    try:\n",
    "        num_agents = len(df_results)\n",
    "        # df_performance = pd.read_csv(performance_table_path)\n",
    "        \n",
    "        # Extract the capacity value from the folder name\n",
    "        # capacity = int(file.split('_cap')[1].split('_')[0])\n",
    "        \n",
    "        # Count each unique value under the column 'Status'\n",
    "        status_counts = df_results['Status'].value_counts().to_dict()\n",
    "        \n",
    "        # Get the number of agents\n",
    "        # num_agents = df_performance['Number_Agents'].iloc[0]\n",
    "        \n",
    "        # Prepare column names specific to this file\n",
    "        # file_key = f\"{file}_cap{auction_time}\"\n",
    "        \n",
    "        \n",
    "        # Add unknown status categories dynamically\n",
    "        for status, count in status_counts.items():\n",
    "            if status not in [\"allocated\", \"delayed\", \"dropped\", \"rebased\", \"parked\"]:\n",
    "                summary_data[file_name][f\"Unknown_{status}\"] = count\n",
    "\n",
    "\n",
    "        df_results[\"Delay\"] = df_results.apply(\n",
    "            lambda row: int(row[\"Allocated Time (Arrival, Departure)\"].split(\" \")[1][:-1].replace(\"'\", \"\")) - \n",
    "                int(row[\"Requested Time (Arrival, Departure)\"].split(\" \")[1][:-1].replace(\"'\", \"\")) if row[\"Status\"] == \"delayed\" else 0,\n",
    "            axis=1)\n",
    "\n",
    "        dropped, rebased_1, rebased_2 = 0, 0, 0\n",
    "        for aircraft, group in df_results.groupby('Aircraft'):\n",
    "            # Reset index within the group so we can use integer positions\n",
    "                group = group.reset_index(drop=True)\n",
    "                for i, row in group.iterrows():\n",
    "                    if row['Status'] == 'rebased':\n",
    "                        if ind >= 2:\n",
    "                            previous_df_2 = df_list[ind-2]\n",
    "                            if aircraft in previous_df_2['Aircraft'].values: \n",
    "                                print(f\"Rebased aircraft {aircraft} was dropped\")\n",
    "                                dropped += 1\n",
    "                                rebases_per_agent[aircraft] = 2\n",
    "                                continue\n",
    "                        if ind >= 1:\n",
    "                            previous_df_1 = df_list[ind-1]\n",
    "                            if aircraft in previous_df_1['Aircraft'].values: \n",
    "                                print(f\"Rebased aircraft {aircraft} was previously rebased\")\n",
    "                                rebased_2 += 1\n",
    "                                rebases_per_agent[aircraft] = 2\n",
    "                                continue\n",
    "                        print(f\"Rebased aircraft {aircraft} is rebasing for the first time\")\n",
    "                        rebases_per_agent[aircraft] = 1\n",
    "                        rebased_1 += 1\n",
    "                        continue\n",
    "                    elif row['Status'] == 'delayed':\n",
    "                        delay_vals.append(row['Delay'])\n",
    "\n",
    "        # Store data in a dictionary format\n",
    "        summary_data[auction_number] = {\n",
    "            # 'Capacity': capacity,\n",
    "            # 'Number_Agents': num_agents,\n",
    "            'Allocated': status_counts.get('allocated', 0),\n",
    "            'Delayed': status_counts.get('delayed', 0),\n",
    "            'Dropped': dropped,\n",
    "            'Rebased Once': rebased_1,\n",
    "            'Rebased Twice': rebased_2,\n",
    "            'Rebased': rebased_1 + rebased_2,\n",
    "            \"Parked\": status_counts.get('parked', 0)\n",
    "        }\n",
    "\n",
    "\n",
    "                \n",
    "        # summary_data[file_key]['Check'] = (\n",
    "        #     summary_data[file_key]['Allocated'] +\n",
    "        #     summary_data[file_key]['Delayed'] +\n",
    "        #     summary_data[file_key]['Dropped'] +\n",
    "        #     summary_data[file_key]['Rebased'] +\n",
    "        #     summary_data[file_key]['Parked'] == num_agents\n",
    "        # )\n",
    "        \n",
    "        summary_data[auction_number][\"Percentage_Allocated\"] = summary_data[auction_number][\"Allocated\"] / num_agents * 100\n",
    "        summary_data[auction_number][\"Percentage_Delayed\"] = summary_data[auction_number][\"Delayed\"] / num_agents * 100\n",
    "        summary_data[auction_number][\"Percentage_Dropped\"] = summary_data[auction_number][\"Dropped\"] / num_agents * 100\n",
    "        summary_data[auction_number][\"Percentage_Rebased\"] = summary_data[auction_number][\"Rebased\"] / num_agents * 100\n",
    "        summary_data[auction_number][\"Percentage_Parked\"] = summary_data[auction_number][\"Parked\"] / num_agents * 100\n",
    "        summary_data[auction_number][\"perfect_dropped_rebased\"] = (summary_data[auction_number][\"Dropped\"] + summary_data[auction_number][\"Rebased\"]) / num_agents * 100\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File not found: {e}\")\n",
    "    except pd.errors.EmptyDataError as e:\n",
    "        print(f\"File is empty: {e}\")\n",
    "    display(df_results)\n",
    "    ind += 1\n",
    "\n",
    "print(f\"Number of rebased agents: {len(rebases_per_agent)}\")\n",
    "print(f\"Number of times rebased: {sum(rebases_per_agent.values())}\")\n",
    "print(f\"Average number of rebases per agent: {sum(rebases_per_agent.values()) / len(rebases_per_agent)}\")\n",
    "print(f\"Average delay: {np.mean(delay_vals)}\")\n",
    "print(f\"Number delayed: {len(delay_vals)}\")\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "if summary_data:\n",
    "    df_status_summary = pd.DataFrame.from_dict(summary_data, orient='index')\n",
    "    df_status_summary.fillna(0, inplace=True)\n",
    "    display(df_status_summary)\n",
    "else:\n",
    "    print(\"No valid data collected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Allocated\", \"Delayed\", \"Dropped\", \"Rebased Once\", \"Rebased Twice\"]\n",
    "color_map = {\"Allocated\": \"purple\", \"Delayed\": \"blue\", \"Dropped\": \"green\", \"Rebased Once\": \"orange\", \"Rebased Twice\": \"brown\"}\n",
    "df_plot = df_status_summary[columns].sort_index()\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "df_plot.plot(kind='bar', stacked=True, ax=ax, zorder=3)\n",
    "ax.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5, zorder=0)  # Grid for better visualization\n",
    "# Labels and Title\n",
    "ax.set_xlabel(\"Auction Number\")\n",
    "ax.set_ylabel(\"Number of Agents\")\n",
    "# ax.set_title(\"Allocations per Auction\")\n",
    "ax.legend(title=\"Status\")\n",
    "\n",
    "ax.tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.savefig(f\"{folder_path}/allocations_per_auction_with_rebase_split.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate MCE with Final Allocation\n",
    "\n",
    "# Find Leftover Resources for Each Auction\n",
    "MCE_list = []\n",
    "for cap, start_cap, price, goods in zip(capacity_list, starting_capacity_list, prices_list, goods_list):\n",
    "    # remaining_capacity = data[\"market_data\"][\"capacity\"][:-2].copy()\n",
    "    # goods_list = data[\"market_data\"][\"goods_list\"]\n",
    "\n",
    "    # for agent, agent_data in data[\"agents_data\"].items():\n",
    "    #     def get_good_allocation(good, agent_data):\n",
    "    #         agent_goods_list = agent_data[\"agent_goods_list\"]\n",
    "    #         final_allocation = agent_data[\"final_allocation\"]\n",
    "    #         if good in agent_goods_list:\n",
    "    #             loc = agent_goods_list.index(good)\n",
    "    #             allocation = final_allocation[loc]\n",
    "    #             return allocation\n",
    "    #         return 0\n",
    "    #     full_allocation = [get_good_allocation(good, agent_data) for good in goods_list[:-2]]\n",
    "    #     remaining_capacity -= full_allocation\n",
    "    #     print(f\"Leftover Resources: {remaining_capacity}\")\n",
    "\n",
    "    total_capacity = sum([start_cap[ind] for ind, good in enumerate(goods) if good[0][0] == \"V\" or good[0].split(\"_\")[0] == good[1].split(\"_\")[0]])\n",
    "\n",
    "    # Sum Leftover Resources for Goods Priced Greater than Zero\n",
    "    non_zero_prices = np.where(price[:-2] > 0.001)[0]\n",
    "    for ind in non_zero_prices:\n",
    "        print(f\"Good {goods[ind]} has price {price[ind]}\")\n",
    "    print(non_zero_prices)\n",
    "    extra_capacity = [cap[ind] for ind in np.where(price[:-2] > 0.001)[0]]\n",
    "    MCE = sum(extra_capacity)/total_capacity*100\n",
    "    MCE_list.append(MCE)\n",
    "    print(f\"Market Clearing Error: {MCE}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.grid(True)\n",
    "plt.plot(list(range(1, len(MCE_list)+1)), MCE_list, marker='o', linestyle=\"--\")\n",
    "plt.xlabel(\"Auction Number\")\n",
    "plt.ylabel(\"Market Clearing Error %\")\n",
    "plt.title(\"Market Clearing Error After Fractional Allocation\")\n",
    "\n",
    "plt.savefig(f\"{folder_path}/market_clearing_error_after_fisher.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of Iterations vs I\n",
    "import math\n",
    "\n",
    "folder_path = \"results/final_runs/toulouse_case_cap7_updated_20_fisher_b-50.0_agentsall_dval40.0_outval1.0_pout1.0_freq30.0_pbound3000.0_beta-method-none_alpha-1.0_receding_20250304_095807/results/\"\n",
    "folder_path = \"results/final_runs/auction_frequency_cap10/\"\n",
    "\n",
    "dfs = []\n",
    "I_values = []\n",
    "for folder in os.listdir(folder_path):\n",
    "    if not folder.startswith(\"t\"):\n",
    "        continue\n",
    "    sub_folder_path = os.path.join(folder_path, f\"{folder}/results\")\n",
    "    period = int(folder.split(\"_\")[4][5:])\n",
    "\n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(sub_folder_path):\n",
    "        csv_path = os.path.join(sub_folder_path, \"market_performance_table.csv\")\n",
    "\n",
    "        if os.path.exists(csv_path):\n",
    "            df = pd.read_csv(csv_path)\n",
    "            df[\"I\"] = int(400/period)\n",
    "            I_values.append(int(400/period))\n",
    "            dfs.append(df)\n",
    "combined_df = pd.concat(dfs, ignore_index=True)         \n",
    "data = [combined_df[combined_df['I'] == I]['Number_Interations'].values for I in I_values]\n",
    "data = [[val for val in row if not math.isnan(val)] for row in data]\n",
    "print(data)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)  # Grid for better visualization\n",
    "meanprops = dict(markeredgecolor='red', markersize=10, linestyle='-', linewidth=2, color='red')\n",
    "plt.boxplot(data, positions=I_values, widths=2, showfliers=False, patch_artist=True,\n",
    "            boxprops=dict(facecolor='lightblue', color='blue'),\n",
    "            capprops=dict(color='blue'),\n",
    "            whiskerprops=dict(color='blue'),\n",
    "            flierprops=dict(color='blue', markeredgecolor='blue'),\n",
    "            medianprops=meanprops)\n",
    "# combined_df = pd.concat(dfs, ignore_index=True)\n",
    "# combined_df = combined_df.sort_values(by=\"I\", key=lambda x: x.astype(float))\n",
    "# plt.plot(df[\"I\"], combined_df[\"Number_Interations\"], marker='o')\n",
    "\n",
    "plt.xlabel(\"Number of Auctions (I)\", fontsize=12)\n",
    "plt.ylabel(\"Number of Iterations\", fontsize=12)\n",
    "# plt.title(\"Number of Iterations Needed \", fontsize=14)\n",
    "# plt.grid(True)\n",
    "# filtered_df = filtered_df.sort_values(by=\"Freq\", key=lambda x: x.astype(float))\n",
    "\n",
    "# plt.plot(filtered_df[\"Freq\"], filtered_df[\"Number_Interations\"], marker='o')\n",
    "# plt.show()\n",
    "plt.savefig(f\"{folder_path}/iter_vs_I.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
